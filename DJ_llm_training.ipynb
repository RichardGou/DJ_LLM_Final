{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11149598,"sourceType":"datasetVersion","datasetId":6956012}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0) requirements","metadata":{}},{"cell_type":"code","source":"# Install required package (if not already installed)\n\n!pip install miditok kagglehub mido pydub\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:13:10.804815Z","iopub.execute_input":"2025-03-25T09:13:10.805105Z","iopub.status.idle":"2025-03-25T09:13:16.728054Z","shell.execute_reply.started":"2025-03-25T09:13:10.805078Z","shell.execute_reply":"2025-03-25T09:13:16.727170Z"}},"outputs":[{"name":"stdout","text":"Collecting miditok\n  Downloading miditok-3.0.5.post1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.9)\nCollecting mido\n  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\nRequirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from miditok) (0.29.0)\nRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from miditok) (1.26.4)\nCollecting symusic>=0.5.0 (from miditok)\n  Downloading symusic-0.5.7-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from miditok) (0.21.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from miditok) (4.67.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from kagglehub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (2.4.1)\nCollecting pySmartDL (from symusic>=0.5.0->miditok)\n  Downloading pySmartDL-1.3.4-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from symusic>=0.5.0->miditok) (4.3.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19->miditok) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19->miditok) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19->miditok) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19->miditok) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19->miditok) (2024.2.0)\nDownloading miditok-3.0.5.post1-py3-none-any.whl (158 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mido-1.3.3-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading symusic-0.5.7-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\nInstalling collected packages: pySmartDL, mido, symusic, miditok\nSuccessfully installed miditok-3.0.5.post1 mido-1.3.3 pySmartDL-1.3.4 symusic-0.5.7\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## b) import dependencies","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport mido\nimport matplotlib.pyplot as plt\n\nfrom miditok import REMI, TokenizerConfig\nfrom miditok.pytorch_data import DatasetMIDI\nfrom pathlib import Path\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2025-03-25T09:13:16.729193Z","iopub.execute_input":"2025-03-25T09:13:16.729427Z","iopub.status.idle":"2025-03-25T09:13:21.068991Z","shell.execute_reply.started":"2025-03-25T09:13:16.729405Z","shell.execute_reply":"2025-03-25T09:13:21.068073Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from miditok import REMI, TokenizerConfig\ntokenizer = REMI.from_pretrained(\"Richatte2000/tokenizer_midi_piano\")","metadata":{"execution":{"iopub.status.busy":"2025-03-25T09:13:21.070272Z","iopub.execute_input":"2025-03-25T09:13:21.070624Z","iopub.status.idle":"2025-03-25T09:13:21.998826Z","shell.execute_reply.started":"2025-03-25T09:13:21.070592Z","shell.execute_reply":"2025-03-25T09:13:21.997877Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.28M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a4c85dba5d145158c4538b25c65acf7"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/miditok/tokenizations/remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n  super().__init__(tokenizer_config, params)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# The following code will only execute\n# successfully when compression is complete\n\"\"\"\nimport kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"pierrepauchet/midi-piano-chunks\")\n\nprint(\"Path to dataset files:\", path)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T22:13:18.320222Z","iopub.execute_input":"2025-03-24T22:13:18.320469Z","iopub.status.idle":"2025-03-24T22:13:18.325091Z","shell.execute_reply.started":"2025-03-24T22:13:18.320447Z","shell.execute_reply":"2025-03-24T22:13:18.324448Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'\\nimport kagglehub\\n\\n# Download latest version\\npath = kagglehub.dataset_download(\"pierrepauchet/midi-piano-chunks\")\\n\\nprint(\"Path to dataset files:\", path)\\n'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from miditok.pytorch_data import DatasetMIDI, DataCollator\nfrom torch.utils.data import DataLoader\nfrom pathlib import Path \n\ntrain_dataset = DatasetMIDI(files_paths=list(Path(\"/kaggle/input/midi-piano-chunks/train\").resolve().glob(\"**/*.mid\")),\n                            tokenizer=tokenizer,\n                            max_seq_len=512,\n                            bos_token_id=tokenizer.pad_token_id,\n                            eos_token_id=tokenizer[\"BOS_None\"],\n)\n\nprint(\"Train dataset loaded\")\nval_dataset = DatasetMIDI(files_paths=list(Path(\"/kaggle/input/midi-piano-chunks/val\").resolve().glob(\"**/*.mid\")),\n                            tokenizer=tokenizer,\n                            max_seq_len=512,\n                            bos_token_id=tokenizer.pad_token_id,\n                            eos_token_id=tokenizer[\"BOS_None\"],\n)\nprint(\"Val dataset loaded\")\ntest_dataset = DatasetMIDI(files_paths=list(Path(\"/kaggle/input/midi-piano-chunks/test\").resolve().glob(\"**/*.mid\")),\n                            tokenizer=tokenizer,\n                            max_seq_len=512,\n                            bos_token_id=tokenizer.pad_token_id,\n                            eos_token_id=tokenizer[\"BOS_None\"]\n)\nprint(\"Test dataset loaded\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:13:21.999760Z","iopub.execute_input":"2025-03-25T09:13:22.000004Z","iopub.status.idle":"2025-03-25T09:16:23.048526Z","shell.execute_reply.started":"2025-03-25T09:13:21.999984Z","shell.execute_reply":"2025-03-25T09:16:23.047757Z"}},"outputs":[{"name":"stdout","text":"Train dataset loaded\nVal dataset loaded\nTest dataset loaded\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Récupération des tokens spéciaux\nspecial_tokens = tokenizer.special_tokens\nspecial_tokens_ids = tokenizer.special_tokens_ids\npad_token, bos_token, eos_token, mask_token = special_tokens\npad_token_id, bos_token_id, eos_token_id, mask_token_id = special_tokens_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:16:23.049656Z","iopub.execute_input":"2025-03-25T09:16:23.049910Z","iopub.status.idle":"2025-03-25T09:16:23.053708Z","shell.execute_reply.started":"2025-03-25T09:16:23.049889Z","shell.execute_reply":"2025-03-25T09:16:23.052809Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom miditok.pytorch_data import DataCollator\n\nclass DataCollatorForInfilling(DataCollator):\n    \"\"\"\n    Data collator qui hérite du DataCollator de miditok et qui ajoute une corruption :\n    pour chaque exemple, on masque UNE séquence contiguë de n tokens (n ~ Poisson(15)).\n    La séquence est choisie aléatoirement parmi tous les tokens valides (excluant BOS et EOS).\n    Les tokens masqués dans l'input sont remplacés par mask_token_id et dans les labels,\n    ces positions conservent la valeur originale (les autres positions sont mises à -100).\n    \"\"\"\n    def __init__(self, pad_token_id, mask_token_id, poisson_lambda=15, copy_inputs_as_labels=True, shift_labels=True):\n        super().__init__(pad_token_id, copy_inputs_as_labels=copy_inputs_as_labels, shift_labels=shift_labels)\n        self.pad_token_id = pad_token_id\n        self.mask_token_id = mask_token_id\n        self.poisson_lambda = poisson_lambda\n\n    def __call__(self, batch):\n\n        batch = super().__call__(batch)\n   \n        inputs = batch[\"input_ids\"].clone()\n        labels = inputs.clone()\n       \n        for i in range(inputs.size(0)):\n            seq = inputs[i]\n            \n            valid_positions = (seq != self.pad_token_id).nonzero(as_tuple=False).view(-1)\n            \n            valid_positions = valid_positions[(valid_positions != 0) & (valid_positions != (seq.size(0) - 1))]\n            if len(valid_positions) == 0:\n                continue\n\n            \n            n_mask = np.random.poisson(self.poisson_lambda)\n            available_length = valid_positions[-1].item() - valid_positions[0].item() + 1\n            \n            span_length = min(n_mask, available_length)\n            if span_length <= 0:\n                continue\n\n            start_idx = np.random.randint(valid_positions[0].item(), valid_positions[-1].item() - span_length + 2)\n            \n            for j in range(start_idx, start_idx + span_length):\n                labels[i, j] = inputs[i, j]      \n                inputs[i, j] = self.mask_token_id \n\n        batch[\"input_ids\"] = inputs\n        batch[\"labels\"] = labels\n        return batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:16:23.054944Z","iopub.execute_input":"2025-03-25T09:16:23.055224Z","iopub.status.idle":"2025-03-25T09:16:23.078386Z","shell.execute_reply.started":"2025-03-25T09:16:23.055197Z","shell.execute_reply":"2025-03-25T09:16:23.077718Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"collator = DataCollatorForInfilling(\n    pad_token_id=tokenizer.pad_token_id,\n    mask_token_id=mask_token_id,\n    poisson_lambda=15,\n    copy_inputs_as_labels=True,\n    shift_labels=True\n)\ntrain_loader = DataLoader(train_dataset, shuffle=True, batch_size=16, collate_fn=collator)\nval_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collator)\ntest_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:16:23.079028Z","iopub.execute_input":"2025-03-25T09:16:23.079285Z","iopub.status.idle":"2025-03-25T09:16:23.099620Z","shell.execute_reply.started":"2025-03-25T09:16:23.079265Z","shell.execute_reply":"2025-03-25T09:16:23.098523Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"sample = next(iter(train_loader))\n\nprint(\"Inpus ID : \",sample['input_ids'][0])\nprint(\"-------------------\")\n\nprint(\"LABELS : \",sample['labels'][0])\nprint(\"-------------------\")\n\nprint(\"Attention MASK : \", sample['attention_mask'][0])\nprint(\"-------------------\")\n\nL_input,L_label,L_attention = sample['input_ids'][0], sample['labels'][0], sample['attention_mask'][0]\n\n#Boucle pour check\nfor i in range(0,len(L_input)):\n    if L_input[i] == mask_token_id:\n        print(\"input : \",L_input[i] ,\"labels : \",L_label[i] ,\"attention mask : \",L_attention[i] )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T09:18:22.191737Z","iopub.execute_input":"2025-03-25T09:18:22.192082Z","iopub.status.idle":"2025-03-25T09:18:22.504782Z","shell.execute_reply.started":"2025-03-25T09:18:22.192056Z","shell.execute_reply":"2025-03-25T09:18:22.503924Z"}},"outputs":[{"name":"stdout","text":"Inpus ID :  tensor([ 3323,   526,  1848,  4089,   533,  1473,   634,  1464,   463,  1377,\n          466,  1693,   607,  1192,  4827,  4944,   589,  1272,   474,  1357,\n          463,  1624,  7537,  5803,   581,  1340,   474,  1289,   509,  2657,\n         4681,  8078,  3427,  6163,  5944,   589,  3065,   507,  2989,   489,\n         1583,  4835,  4987,  6177,  6163,   530,  4051,   530,  1557,  2570,\n         2890,  2709,  4801,   474,  1468,  3946,  6039,  3563,  5369,   549,\n         4048,   466,  3998, 17288,  5284, 10866,  3374,   521,  6123,   453,\n         3725,   453,  1423,  5388,  3424,  5385,   558,  4670,   466,  4741,\n          493,  1316,   516,  1897,  4533,  3500,  3235,   535,  1581,  8800,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,   460,\n         3301,   849,  9718,  2938,  6027,  1974, 16684,  2077,  1994,  1748,\n         7319,   534,  2306,  6015,  6287, 11772,  3666,   481,  1475,  1553,\n        15717,   570,  4685,  1199,   929, 15138,  3762,  2458,  5356,  2975,\n          453,  1619,  1553,  3215,   465,  1851,  3903,  1764,  6591,  2168,\n        15465,  3710,  3762,  5449, 14279,  1730,  1553, 17959, 12459,  1589,\n         3992,  5149,  5026,  4172,  3605, 14166,  2249,   463,  1218, 12459,\n         1843,  7547,  3001,  3928,  5449,  5325,   500,  1492,  1553,   453,\n         1521,  1553,   433,  1945,  3813,  3495,  5014,  2622, 16822,  2195,\n         1026,   870,   468,  2568,  6591,  2090,  6612,  2765,  4918,  3827,\n         6663,  2487,   515,  1505,  1553,  2622,   477,  1550,  1553, 14063,\n         3688,  7199,  5325,  3378,  4172,   488,  1328,  2593,   461,  1489,\n         2451,   465,  2337,  5167,  4300,  6950,  6982,  3461,  7422,   561,\n         3159,  8800,   466,  3528,  4874,   800,   458,  4984,  1825,  7497,\n         6278,  4405,  7415, 10259,   791,   541, 16960,   466,  2876,  3845,\n         6047,  1358,  3207, 11757,  4013,   498,  2956,  8638, 11548, 10077,\n         4091,  5558,   554,  9763,  6558,   466,  4072, 15788,   845,   472,\n         7547,  5202,  6641,  7889,  8098,   850,   658,  5294,   491,  3877,\n        12411,  1240,   435,  7750,  7994,  6643,  8086,  2767,   506,  5091,\n         3461,   575,  2921,  9603,  9867,  3512,   466,  2430, 16002,  2815,\n         2957,  1166,  5238,  1820,   879,   482,  2183,   693,  1483,  6047,\n          878,   462,  2676,  3962,  4593,   794,   468,  7165,  3113,  4137,\n         6050,  5350,  3343,   628,  2786,  8312, 14074,  1334,  2878,  1095,\n         1166,   459,  1306,   473,  6437,   491,  3583,  4549, 14898,   800,\n          464,  3608,  1825,   515,  1699,   855,   468,  3853,  5575,  3453,\n          461,  1350,   576,  2869,  5320,  1026,   452,  1532,   879,   464,\n         5164,  1825,   575,  1557,   461,  1469,   534,  2901,  4897,   598,\n         2795,  4549,  1433,   814,  5415,  2313,  2183,  7535,   853,  6183,\n         2337,  4371,  5575,   575,  5120,  7118,   459, 13061,  3894,   914,\n          566,   453,  3133,   675,  1948,   477,  1637, 16723,  2306, 18241,\n         1480,  1357,   587,  1482,  2176,  2107,   522,  1859,  2575,   465,\n         1561,  2371,   499,  1287,  8317,  1866,   498,  1289,   584,   979,\n        12215,  2163,   456,  3934,  5248,   667,  2201,  1394,   667,  1844,\n         3010,   960, 19685,   682,  1987,   806,  9708,  2022,   846, 14725,\n         1167,  4524, 12921,   498,  1843,  2566,   499,  1569,  4867,   452,\n         2446,  1783,  2237,   893,  8927,  1595,  4273,  2703,   439,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0])\n-------------------\nLABELS :  tensor([ 3323,   526,  1848,  4089,   533,  1473,   634,  1464,   463,  1377,\n          466,  1693,   607,  1192,  4827,  4944,   589,  1272,   474,  1357,\n          463,  1624,  7537,  5803,   581,  1340,   474,  1289,   509,  2657,\n         4681,  8078,  3427,  6163,  5944,   589,  3065,   507,  2989,   489,\n         1583,  4835,  4987,  6177,  6163,   530,  4051,   530,  1557,  2570,\n         2890,  2709,  4801,   474,  1468,  3946,  6039,  3563,  5369,   549,\n         4048,   466,  3998, 17288,  5284, 10866,  3374,   521,  6123,   453,\n         3725,   453,  1423,  5388,  3424,  5385,   558,  4670,   466,  4741,\n          493,  1316,   516,  1897,  4533,  3500,  3235,   535,  1581,  8800,\n          466,  7047,  3973,  2390,  3315,   473,  1307,  3277,  2706,  5442,\n          556,  6494,  2451,   433,  3079,  3962,   934,  4874,   870,   460,\n         3301,   849,  9718,  2938,  6027,  1974, 16684,  2077,  1994,  1748,\n         7319,   534,  2306,  6015,  6287, 11772,  3666,   481,  1475,  1553,\n        15717,   570,  4685,  1199,   929, 15138,  3762,  2458,  5356,  2975,\n          453,  1619,  1553,  3215,   465,  1851,  3903,  1764,  6591,  2168,\n        15465,  3710,  3762,  5449, 14279,  1730,  1553, 17959, 12459,  1589,\n         3992,  5149,  5026,  4172,  3605, 14166,  2249,   463,  1218, 12459,\n         1843,  7547,  3001,  3928,  5449,  5325,   500,  1492,  1553,   453,\n         1521,  1553,   433,  1945,  3813,  3495,  5014,  2622, 16822,  2195,\n         1026,   870,   468,  2568,  6591,  2090,  6612,  2765,  4918,  3827,\n         6663,  2487,   515,  1505,  1553,  2622,   477,  1550,  1553, 14063,\n         3688,  7199,  5325,  3378,  4172,   488,  1328,  2593,   461,  1489,\n         2451,   465,  2337,  5167,  4300,  6950,  6982,  3461,  7422,   561,\n         3159,  8800,   466,  3528,  4874,   800,   458,  4984,  1825,  7497,\n         6278,  4405,  7415, 10259,   791,   541, 16960,   466,  2876,  3845,\n         6047,  1358,  3207, 11757,  4013,   498,  2956,  8638, 11548, 10077,\n         4091,  5558,   554,  9763,  6558,   466,  4072, 15788,   845,   472,\n         7547,  5202,  6641,  7889,  8098,   850,   658,  5294,   491,  3877,\n        12411,  1240,   435,  7750,  7994,  6643,  8086,  2767,   506,  5091,\n         3461,   575,  2921,  9603,  9867,  3512,   466,  2430, 16002,  2815,\n         2957,  1166,  5238,  1820,   879,   482,  2183,   693,  1483,  6047,\n          878,   462,  2676,  3962,  4593,   794,   468,  7165,  3113,  4137,\n         6050,  5350,  3343,   628,  2786,  8312, 14074,  1334,  2878,  1095,\n         1166,   459,  1306,   473,  6437,   491,  3583,  4549, 14898,   800,\n          464,  3608,  1825,   515,  1699,   855,   468,  3853,  5575,  3453,\n          461,  1350,   576,  2869,  5320,  1026,   452,  1532,   879,   464,\n         5164,  1825,   575,  1557,   461,  1469,   534,  2901,  4897,   598,\n         2795,  4549,  1433,   814,  5415,  2313,  2183,  7535,   853,  6183,\n         2337,  4371,  5575,   575,  5120,  7118,   459, 13061,  3894,   914,\n          566,   453,  3133,   675,  1948,   477,  1637, 16723,  2306, 18241,\n         1480,  1357,   587,  1482,  2176,  2107,   522,  1859,  2575,   465,\n         1561,  2371,   499,  1287,  8317,  1866,   498,  1289,   584,   979,\n        12215,  2163,   456,  3934,  5248,   667,  2201,  1394,   667,  1844,\n         3010,   960, 19685,   682,  1987,   806,  9708,  2022,   846, 14725,\n         1167,  4524, 12921,   498,  1843,  2566,   499,  1569,  4867,   452,\n         2446,  1783,  2237,   893,  8927,  1595,  4273,  2703,   439,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0])\n-------------------\nAttention MASK :  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n-------------------\ninput :  tensor(3) labels :  tensor(466) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(7047) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(3973) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(2390) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(3315) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(473) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(1307) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(3277) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(2706) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(5442) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(556) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(6494) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(2451) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(433) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(3079) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(3962) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(934) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(4874) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(870) attention mask :  tensor(1, dtype=torch.int32)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## bart training","metadata":{}},{"cell_type":"code","source":"#############################\n# Définition du modèle BART de base (non pré-entraîné)\n#############################\nfrom transformers import BartConfig, BartForConditionalGeneration\n\nconfig = BartConfig(\n    vocab_size=tokenizer.vocab_size,\n    max_position_embeddings=1024,\n    encoder_layers=6,\n    decoder_layers=6,\n    encoder_attention_heads=8,\n    decoder_attention_heads=8,\n    d_model=512,\n    bos_token_id=bos_token_id,\n    eos_token_id=eos_token_id,\n    pad_token_id=pad_token_id,\n    mask_token_id=mask_token_id\n)\n#model = BartForConditionalGeneration(config)\n#model = model.to(device)\n\nmodel = BartForConditionalGeneration.from_pretrained(\"Richatte2000/model-from-trained-trained-epoch-0\").to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T10:00:24.461026Z","iopub.execute_input":"2025-03-25T10:00:24.461345Z","iopub.status.idle":"2025-03-25T10:00:29.494998Z","shell.execute_reply.started":"2025-03-25T10:00:24.461322Z","shell.execute_reply":"2025-03-25T10:00:29.494285Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3491: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61b3171148094fefa4803236952410c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/323M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e635b5dca1c34673bc812fddee76ad1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b328b863370f423aaf437c6d5a9bff51"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\n\noptimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\nnum_epochs = 10\ntotal_steps = len(train_loader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=int(0.1 * total_steps),\n                                            num_training_steps=total_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T10:01:49.845846Z","iopub.execute_input":"2025-03-25T10:01:49.846135Z","iopub.status.idle":"2025-03-25T10:01:49.853501Z","shell.execute_reply.started":"2025-03-25T10:01:49.846114Z","shell.execute_reply":"2025-03-25T10:01:49.852682Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"#############################\n# Boucle d'entraînement avec évaluation sur la validation et push sur Hugging Face\n#############################\nfor epoch in range(num_epochs):\n    model.train()\n    total_train_loss = 0\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    for batch in progress_bar:\n        # Déplacement des données vers le device\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        \n        # Clipping des gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        \n        total_train_loss += loss.item()\n        progress_bar.set_postfix({\"loss\": loss.item()})\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n    \n    # Évaluation sur le jeu de validation\n    model.eval()\n    total_val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            total_val_loss += outputs.loss.item()\n    avg_val_loss = total_val_loss / len(val_loader)\n    \n    print(f\"\\nEpoch {epoch+1} terminé : Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f}\\n\")\n    \n    # Push du modèle sur Hugging Face Hub\n    # Remplacez \"USERNAME/REPO_NAME\" et \"YOUR_TOKEN\" par vos identifiants et token.\n    model.push_to_hub(\"Richatte2000/model-from-trained-trained-epoch-\"+str(epoch), use_auth_token=\"hidden\", commit_message=f\"Epoch {epoch+1}\")\n    model.save_pretrained(\"model-trained-epoch-\"+str(epoch))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T10:02:06.151875Z","iopub.execute_input":"2025-03-25T10:02:06.152173Z","iopub.status.idle":"2025-03-25T12:26:38.652009Z","shell.execute_reply.started":"2025-03-25T10:02:06.152146Z","shell.execute_reply":"2025-03-25T12:26:38.650881Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 4615/4615 [2:09:45<00:00,  1.69s/it, loss=0.167]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 terminé : Train Loss = 0.2011 | Val Loss = 0.1914\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:894: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/323M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bae921f0044f47218d18a0e83fc2aabe"}},"metadata":{}},{"name":"stderr","text":"Epoch 2/10:   6%|▌         | 285/4615 [07:49<1:58:59,  1.65s/it, loss=0.176]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-b3d37fff2f9a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Clipping des gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":21},{"cell_type":"markdown","source":"# Entrainement en remplacant une lkiste masqué par un seul mask","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom miditok.pytorch_data import DataCollator\n\n# Retrieve special tokens\nspecial_tokens = tokenizer.special_tokens\nspecial_tokens_ids = tokenizer.special_tokens_ids\npad_token, bos_token, eos_token, mask_token = special_tokens\npad_token_id, bos_token_id, eos_token_id, mask_token_id = special_tokens_ids\n\nclass DataCollatorForInfilling(DataCollator):\n    \"\"\"\n    Data collator that inherits from miditok's DataCollator and adds corruption:\n    For each example, mask ONE contiguous sequence of n tokens (n ~ Poisson(15)).\n    The sequence is randomly chosen from all valid tokens (excluding BOS and EOS).\n\n    Modifications:\n      - In the input, the masked sequence is replaced by a SINGLE mask_token.\n      - The \"missing\" tokens (span_length - 1) are added at the END as pad tokens,\n        to maintain the same length as the original.\n      - In the labels, the position corresponding to the first masked token keeps the original value,\n        while other positions in the masked span are set to -100.\n    \"\"\"\n    def __init__(self, pad_token_id, mask_token_id, poisson_lambda=15, copy_inputs_as_labels=True, shift_labels=True):\n        super().__init__(pad_token_id, copy_inputs_as_labels=copy_inputs_as_labels, shift_labels=shift_labels)\n        self.pad_token_id = pad_token_id\n        self.mask_token_id = mask_token_id\n        self.poisson_lambda = poisson_lambda\n\n    def __call__(self, batch):\n        # Apply the base collator for padding and label shifting if requested\n        batch = super().__call__(batch)\n        inputs = batch[\"input_ids\"].clone()\n        labels = batch[\"input_ids\"].clone()  # Start with a copy of inputs\n\n        # For each example in the batch\n        for i in range(inputs.size(0)):\n            seq = inputs[i]\n            L = seq.size(0)\n            # Get valid positions (non-padding)\n            valid_positions = (seq != self.pad_token_id).nonzero(as_tuple=False).view(-1)\n            # Exclude the first and last token (often BOS and EOS)\n            valid_positions = valid_positions[(valid_positions != 0) & (valid_positions != (L - 1))]\n            if len(valid_positions) == 0:\n                continue\n\n            # Number of tokens to mask according to a Poisson distribution\n            n_mask = np.random.poisson(self.poisson_lambda)\n\n            # Calculate the available length in the contiguous sequence of valid tokens\n            available_length = valid_positions[-1].item() - valid_positions[0].item() + 1\n            span_length = min(n_mask, available_length)\n            if span_length <= 0:\n                continue\n\n            # Randomly choose a start index such that the masked block stays within valid positions\n            start_idx = np.random.randint(valid_positions[0].item(), valid_positions[-1].item() - span_length + 2)\n\n            # Modify the input\n            input_before = seq[:start_idx]\n            input_after = seq[start_idx + span_length:]\n            new_seq = torch.cat([input_before, torch.tensor([self.mask_token_id], dtype=seq.dtype), input_after])\n            # Calculate the number of removed tokens (span_length - 1) and add pad tokens at the END\n            num_removed = span_length - 1\n            if num_removed > 0:\n                padding = torch.full((num_removed,), self.pad_token_id, dtype=seq.dtype)\n                new_seq = torch.cat([new_seq, padding])\n            # Ensure the new sequence has the same length as the original\n            if new_seq.size(0) != L:\n                if new_seq.size(0) > L:\n                    new_seq = new_seq[:L]\n                else:\n                    pad_extra = torch.full((L - new_seq.size(0),), self.pad_token_id, dtype=seq.dtype)\n                    new_seq = torch.cat([new_seq, pad_extra])\n            inputs[i] = new_seq\n\n        batch[\"input_ids\"] = inputs\n        batch[\"labels\"] = labels\n        return batch\n\ncollator = DataCollatorForInfilling(\n    pad_token_id=tokenizer.pad_token_id,\n    mask_token_id=mask_token_id,\n    poisson_lambda=15,\n    copy_inputs_as_labels=True,\n    shift_labels=True\n)\ntrain_loader = DataLoader(train_dataset, shuffle=True, batch_size=16, collate_fn=collator)\nval_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collator)\ntest_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collator)\n\nsample = next(iter(train_loader))\n\nprint(\"Input IDs: \", sample['input_ids'][0])\nprint(\"-------------------\")\n\nprint(\"Labels: \", sample['labels'][0])\nprint(\"-------------------\")\n\nprint(\"Attention Mask: \", sample['attention_mask'][0])\nprint(\"-------------------\")\n\nL_input, L_label, L_attention = sample['input_ids'][0], sample['labels'][0], sample['attention_mask'][0]\n\n# Loop to check masked positions\nfor i in range(len(L_input)):\n    if L_input[i] == mask_token_id:\n        print(\"Input: \", L_input[i], \"Label: \", L_label[i], \"Attention Mask: \", L_attention[i])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:43:52.273598Z","iopub.execute_input":"2025-03-25T12:43:52.273964Z","iopub.status.idle":"2025-03-25T12:43:52.513439Z","shell.execute_reply.started":"2025-03-25T12:43:52.273936Z","shell.execute_reply":"2025-03-25T12:43:52.512708Z"}},"outputs":[{"name":"stdout","text":"Inpus ID :  tensor([ 1988,  5920,  4992,  8891,   563,  2702,   563,  1583, 15900,   561,\n         1010,   515,  1599,  2247,  5111, 14773,  1451,  3251,  3245,  5413,\n          559,  3086, 16772,  4514, 17712, 13090,  6576,   748,  1031,  7039,\n          571,  1877,  6113,  7349,  8651, 12964,   607,  1262,  3505,  3132,\n          530,  4555,   547,  3065,  7940,  7483,   524,  2116,   522,  1529,\n         2671, 17614,  3172, 13894,  1859,  4165,  1103,  1066,   788,   472,\n         7296,  6463,  5064,  6044,  8856,   593, 14807,   607,  2225,   595,\n         1045,  4990,  8618,  6706,  5064,   593,  1042,   628,  2756,   530,\n          987,  5078,  5166,   504,  1121,   560,  1445,   674,  1934,   499,\n         1216,  4287,  7929,  7249,  5475,  3380,   608,  1975,  8208,  3348,\n         2822,  1190,  4546, 14137,  2364,   421,  9024,  1968,   434, 13066,\n         1850,  3310,  1621,   434,  8709,   996,   431,     3,   547,  2637,\n         5272,  7394,  5052,   506,   989,  6402,   585,  1779,  7137,   593,\n         1012,  4717,  4352,  2734,   513,  2758,  4504,  5051,  3162, 19237,\n         1835,  8881,  5763, 10690,  2886,   567,  1832,  3892, 19011,  1355,\n        14499,  6159,  8856,  7026,   585,  1224,  4461,  4218,   586,  2563,\n         6159,  7540, 11198,   551,  1403,  4352,   892,  4331,   477,  2917,\n          491,  1325,   779,   984,  4848, 17219,   554,  1071,  9013,  7937,\n          635,   987,  2053,  6454,  7380,  4458,   567,  1037,  4460,  9367,\n          675,  2716,   500,  2007,  4776,  1716,  5156,   454,  8292,   418,\n         6107,   431,  5156,   423,  1824,  1685,  3991,   411,  3616,  2091,\n         2061,  4861,  1398,  5343,   940,  6456,  1588,  6792,  1791,  6680,\n          411,  2506,  1188,  2723,  2248,  1967,   671,  1546,   622,  1136,\n        13901,  1729,    54, 13823,  1070,  1005,   535,  3645,   463,  1821,\n        15390,  9553,  9211,   739,  1629,   678,  2926,  2260,  1498,   513,\n          987,   854,  1328,  7260,  1786,   450,  1697,  6123,   734,  2122,\n          708,  1422,  9110,   673,  1477,   636,  1669,   624,   990,   523,\n          915,  8019,  6739,   678,  1102,  9301,   690,   982,   586,  1214,\n          474,  2108,   481,  1848, 12732,   694,  1901, 10951, 12782,   689,\n         1048,   549,  1017,   643,  1674, 17433,   650,  1989,   516,  4628,\n         9582,   643,  1864,  1014,   626, 10548,   618,  1174,   526,  1690,\n         5570,  2294,  4427,   602,  1080,   585,  1967,   602,  1131,   500,\n         1078,  5915,  7052,   602,   555,  8995,   602,  1106,   554,  2991,\n          672,   984,  7544,   623,  1592,  4503,  4254,   526,  1224,  7696,\n         3095,  8949,   640,  2775,  4274,  5904,  5009,   546,  1318, 12695,\n        11956,   721,   460,  1786,   950,   487,   915,   509,  3836,  5424,\n          686,  1037,   535,  1342,   745,   420,   700,  1299,  1290,   450,\n          698,   517,  1150,  9439,  7987,   677,   933,  1076,   424,  2867,\n          436,  2867,   460,  2867,   411,  6273,   612,  2712,  5622,  1313,\n         5508,  1662,  4675,  1244,  4675,   983,  1931,  1570,  4435,  8233,\n         4251,   411,  3447,   703,  2103,   734,   445,  1869,  1548,  1786,\n          428,  1470,  1482,   623,  2073,   716,   421,  6909,  1704,   429,\n         3108,   428,   716,  1012,   549,  2065,   499,  1826,  2974,   623,\n         1822, 14707, 18235,  1178,  1486,   530,  1043,  9750,  1178,   428,\n        18879,  3108,  4188,   765,  1848,  6145,   765,   432,   703,  1775,\n        12099, 13530,  1333,  1529,   526,  3695,   753,   418, 10929,   816,\n          938,  2191,  9607,   664,  1278,   810,   970,  2897,   848,  1911,\n         6871,   677,  1214,   489,  2832,   493,  2154, 10799,   640,  1473,\n         8527,   666,  1053,   549,  2692,  8491,  9157, 10875,   689,  1985,\n          558,  8697, 10936,   654,   626,   697,  1501,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0])\n-------------------\nLABELS :  tensor([ 1988,  5920,  4992,  8891,   563,  2702,   563,  1583, 15900,   561,\n         1010,   515,  1599,  2247,  5111, 14773,  1451,  3251,  3245,  5413,\n          559,  3086, 16772,  4514, 17712, 13090,  6576,   748,  1031,  7039,\n          571,  1877,  6113,  7349,  8651, 12964,   607,  1262,  3505,  3132,\n          530,  4555,   547,  3065,  7940,  7483,   524,  2116,   522,  1529,\n         2671, 17614,  3172, 13894,  1859,  4165,  1103,  1066,   788,   472,\n         7296,  6463,  5064,  6044,  8856,   593, 14807,   607,  2225,   595,\n         1045,  4990,  8618,  6706,  5064,   593,  1042,   628,  2756,   530,\n          987,  5078,  5166,   504,  1121,   560,  1445,   674,  1934,   499,\n         1216,  4287,  7929,  7249,  5475,  3380,   608,  1975,  8208,  3348,\n         2822,  1190,  4546, 14137,  2364,   421,  9024,  1968,   434, 13066,\n         1850,  3310,  1621,   434,  8709,   996,   431,   910,   424,   735,\n          445,   831,  9830,  4407,  4848,   654,   472,  9624,   654,  2738,\n          594,  2185,   547,  2637,  5272,  7394,  5052,   506,   989,  6402,\n          585,  1779,  7137,   593,  1012,  4717,  4352,  2734,   513,  2758,\n         4504,  5051,  3162, 19237,  1835,  8881,  5763, 10690,  2886,   567,\n         1832,  3892, 19011,  1355, 14499,  6159,  8856,  7026,   585,  1224,\n         4461,  4218,   586,  2563,  6159,  7540, 11198,   551,  1403,  4352,\n          892,  4331,   477,  2917,   491,  1325,   779,   984,  4848, 17219,\n          554,  1071,  9013,  7937,   635,   987,  2053,  6454,  7380,  4458,\n          567,  1037,  4460,  9367,   675,  2716,   500,  2007,  4776,  1716,\n         5156,   454,  8292,   418,  6107,   431,  5156,   423,  1824,  1685,\n         3991,   411,  3616,  2091,  2061,  4861,  1398,  5343,   940,  6456,\n         1588,  6792,  1791,  6680,   411,  2506,  1188,  2723,  2248,  1967,\n          671,  1546,   622,  1136, 13901,  1729,    54, 13823,  1070,  1005,\n          535,  3645,   463,  1821, 15390,  9553,  9211,   739,  1629,   678,\n         2926,  2260,  1498,   513,   987,   854,  1328,  7260,  1786,   450,\n         1697,  6123,   734,  2122,   708,  1422,  9110,   673,  1477,   636,\n         1669,   624,   990,   523,   915,  8019,  6739,   678,  1102,  9301,\n          690,   982,   586,  1214,   474,  2108,   481,  1848, 12732,   694,\n         1901, 10951, 12782,   689,  1048,   549,  1017,   643,  1674, 17433,\n          650,  1989,   516,  4628,  9582,   643,  1864,  1014,   626, 10548,\n          618,  1174,   526,  1690,  5570,  2294,  4427,   602,  1080,   585,\n         1967,   602,  1131,   500,  1078,  5915,  7052,   602,   555,  8995,\n          602,  1106,   554,  2991,   672,   984,  7544,   623,  1592,  4503,\n         4254,   526,  1224,  7696,  3095,  8949,   640,  2775,  4274,  5904,\n         5009,   546,  1318, 12695, 11956,   721,   460,  1786,   950,   487,\n          915,   509,  3836,  5424,   686,  1037,   535,  1342,   745,   420,\n          700,  1299,  1290,   450,   698,   517,  1150,  9439,  7987,   677,\n          933,  1076,   424,  2867,   436,  2867,   460,  2867,   411,  6273,\n          612,  2712,  5622,  1313,  5508,  1662,  4675,  1244,  4675,   983,\n         1931,  1570,  4435,  8233,  4251,   411,  3447,   703,  2103,   734,\n          445,  1869,  1548,  1786,   428,  1470,  1482,   623,  2073,   716,\n          421,  6909,  1704,   429,  3108,   428,   716,  1012,   549,  2065,\n          499,  1826,  2974,   623,  1822, 14707, 18235,  1178,  1486,   530,\n         1043,  9750,  1178,   428, 18879,  3108,  4188,   765,  1848,  6145,\n          765,   432,   703,  1775, 12099, 13530,  1333,  1529,   526,  3695,\n          753,   418, 10929,   816,   938,  2191,  9607,   664,  1278,   810,\n          970,  2897,   848,  1911,  6871,   677,  1214,   489,  2832,   493,\n         2154, 10799,   640,  1473,  8527,   666,  1053,   549,  2692,  8491,\n         9157, 10875,   689,  1985,   558,  8697, 10936,   654,   626,   697,\n         1501])\n-------------------\nAttention MASK :  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n-------------------\ninput :  tensor(3) labels :  tensor(910) attention mask :  tensor(1, dtype=torch.int32)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"#############################\n# Définition du modèle BART de base (non pré-entraîné)\n#############################\nfrom transformers import BartConfig, BartForConditionalGeneration\n\nconfig = BartConfig(\n    vocab_size=tokenizer.vocab_size,\n    max_position_embeddings=1024,\n    encoder_layers=6,\n    decoder_layers=6,\n    encoder_attention_heads=8,\n    decoder_attention_heads=8,\n    d_model=512,\n    bos_token_id=bos_token_id,\n    eos_token_id=eos_token_id,\n    pad_token_id=pad_token_id,\n    mask_token_id=mask_token_id\n)\n#model = BartForConditionalGeneration(config)\n#model = model.to(device)\n\nmodel = BartForConditionalGeneration.from_pretrained(\"Richatte2000/model-from-trained-trained-epoch-0\").to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T12:44:14.003099Z","iopub.execute_input":"2025-03-25T12:44:14.003374Z","iopub.status.idle":"2025-03-25T12:44:20.284123Z","shell.execute_reply.started":"2025-03-25T12:44:14.003352Z","shell.execute_reply":"2025-03-25T12:44:20.283311Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3491: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e02ab9890cc54d85b12d9a56e0c2ee6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/323M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7b4f25a9bfe46ef8ae5658780db51ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77dc607ace5e4eaf9d2a18543a2c2af9"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\n\noptimizer = AdamW(model.parameters(), lr=8e-4, weight_decay=0.01)\nnum_epochs = 10\ntotal_steps = len(train_loader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=int(0.1 * total_steps),\n                                            num_training_steps=total_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:11:06.218195Z","iopub.execute_input":"2025-03-25T17:11:06.218464Z","iopub.status.idle":"2025-03-25T17:11:06.225822Z","shell.execute_reply.started":"2025-03-25T17:11:06.218441Z","shell.execute_reply":"2025-03-25T17:11:06.225107Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"#############################\n# Boucle d'entraînement avec évaluation sur la validation et push sur Hugging Face\n#############################\nfor epoch in range(num_epochs):\n    model.train()\n    total_train_loss = 0\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    for batch in progress_bar:\n        # Déplacement des données vers le device\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        \n        # Clipping des gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        \n        total_train_loss += loss.item()\n        progress_bar.set_postfix({\"loss\": loss.item()})\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n    \n    # Évaluation sur le jeu de validation\n    model.eval()\n    total_val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            total_val_loss += outputs.loss.item()\n    avg_val_loss = total_val_loss / len(val_loader)\n    \n    print(f\"\\nEpoch {epoch+1} terminé : Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f}\\n\")\n    \n    # Push du modèle sur Hugging Face Hub\n    # Remplacez \"USERNAME/REPO_NAME\" et \"YOUR_TOKEN\" par vos identifiants et token.\n    model.push_to_hub(\"Richatte2000/model-mask-one-epoch-\"+str(epoch), commit_message=f\"Epoch {epoch+1}\")\n    model.save_pretrained(\"model-trained-epoch-\"+str(epoch))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T17:11:09.972992Z","iopub.execute_input":"2025-03-25T17:11:09.973266Z","execution_failed":"2025-03-25T21:12:23.806Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 4615/4615 [2:06:40<00:00,  1.65s/it, loss=0.968]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 terminé : Train Loss = 1.7935 | Val Loss = 0.8704\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:894: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e72ea6eeeab64459825dde6d3d10d170"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/323M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3de5404e8a4b423f84f01faa23e99f65"}},"metadata":{}},{"name":"stderr","text":"Epoch 2/10:  85%|████████▌ | 3944/4615 [1:48:11<18:17,  1.64s/it, loss=0.363]  ","output_type":"stream"}],"execution_count":null}]}